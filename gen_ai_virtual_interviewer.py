# -*- coding: utf-8 -*-
"""gen_ai_virtual_interviewer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nO-pc_c5phyzJ475MT1JSkru2gIptd9B
"""

# === Required Packages Installation ===
!pip install pdfplumber gradio transformers sentencepiece speechrecognition pyaudio pydub --quiet
!apt-get install -y portaudio19-dev python3-all-dev

!pip install SpeechRecognition
!pip install pyaudio
!pip install pdfplumber

# === Imports ===
from transformers import pipeline
import gradio as gr
import speech_recognition as sr
from pydub import AudioSegment
import pdfplumber
import tempfile
import os
import re

# === Load FLAN-T5 Model ===
qa_pipeline = pipeline("text2text-generation", model="google/flan-t5-base")

# === Resume Text Chunking ===
def split_resume(resume_text, max_len=512):
    words = resume_text.split()
    chunks, chunk = [], []

    for word in words:
        chunk.append(word)
        if len(" ".join(chunk)) > max_len:
            chunks.append(" ".join(chunk[:-1]))
            chunk = [word]

    if chunk:
        chunks.append(" ".join(chunk))
    return chunks

# === Extract Text from PDF ===
def extract_text_from_pdf(pdf_file):
    text = ""
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            text += page.extract_text() + "\n"
    return text.strip()

# === Question Generator ===
def generate_questions_from_resume(resume_text, num_questions=5):
    resume_chunks = split_resume(resume_text)
    questions = []

    for chunk in resume_chunks:
        result = qa_pipeline(
            f"Generate {num_questions} technical interview questions based on the following resume:\n{chunk}",
            max_length=256,
            do_sample=True,
            temperature=0.7,
        )
        generated_text = result[0]['generated_text']
        extracted = re.findall(r"[\-â€¢]?\s*(.*?)(?:\?|$)", generated_text)
        questions += [q.strip("â€¢-â€“1234567890. \n") for q in extracted if q.strip()]

    return questions[:num_questions]

# === Audio Transcription ===
def transcribe_audio(audio_file):
    recognizer = sr.Recognizer()
    sound = AudioSegment.from_file(audio_file)

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
        temp_wav = tmpfile.name
        sound.export(temp_wav, format="wav")

    try:
        with sr.AudioFile(temp_wav) as source:
            audio = recognizer.record(source)
            text = recognizer.recognize_google(audio)
    except sr.UnknownValueError:
        text = "Could not understand the audio."
    except sr.RequestError:
        text = "Speech recognition service error."
    finally:
        os.remove(temp_wav)

    return text

# === Answer Scoring ===
def score_answer_with_context(answer, resume, question):
    prompt = f"""You are an interview evaluator.

Resume:
{resume}

Question:
{question}

Candidate's Answer:
{answer}

Evaluate the answer on a scale of 1 to 10 (only return a number):"""

    result = qa_pipeline(prompt, max_new_tokens=10)[0]['generated_text']

    try:
        score = int(''.join(filter(str.isdigit, result.strip())))
        score = min(max(score, 1), 10)
    except:
        score = "N/A"
    return str(score)

# === Gradio App ===
with gr.Blocks() as app:
    gr.Markdown("# AI Interviewer with Voice Response and PDF Resume")

    with gr.Row():
        resume_pdf = gr.File(label="ðŸ“„ Upload Resume (PDF Only)", type="filepath")
        resume_text_output = gr.Textbox(label="ðŸ“ƒ Extracted Resume Text", lines=10)

    generate_btn = gr.Button("Generate Interview Questions")
    question_list = gr.Dropdown(choices=[], label="Pick a Question")

    mic_input = gr.Audio(type="filepath", label="Record Your Answer")
    evaluate_btn = gr.Button("Evaluate Answer")

    transcript_output = gr.Textbox(label="Transcript of Your Answer")
    feedback_output = gr.Textbox(label="Score (1-10)")

    questions_holder = gr.State([])
    resume_holder = gr.State("")

    def extract_and_store(pdf_path):
        text = extract_text_from_pdf(pdf_path)
        return text, text

    def generate_questions(resume):
        questions = generate_questions_from_resume(resume)
        return gr.update(choices=questions, value=questions[0] if questions else None), questions

    def evaluate(audio, question, resume, questions):
        if not question:
            return "Please select a question.", "N/A"
        transcript = transcribe_audio(audio)
        score = score_answer_with_context(transcript, resume, question)
        return transcript, score

    resume_pdf.change(extract_and_store, inputs=resume_pdf, outputs=[resume_text_output, resume_holder])
    generate_btn.click(generate_questions, inputs=resume_holder, outputs=[question_list, questions_holder])
    evaluate_btn.click(evaluate, inputs=[mic_input, question_list, resume_holder, questions_holder],
                       outputs=[transcript_output, feedback_output])

app.launch()